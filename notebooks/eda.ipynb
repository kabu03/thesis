{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f059e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from src.config import SPECIFIC_INCIDENT_NUMS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa156ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output dir + helper\n",
    "from pathlib import Path\n",
    "EDA_PLOTS_DIR = Path('visualizations/eda')\n",
    "EDA_PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_and_close(fig, filename):\n",
    "    name_pdf = Path(filename).with_suffix('.pdf').name\n",
    "    out = EDA_PLOTS_DIR / name_pdf\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out, format='pdf', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd0e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_specific_df = []\n",
    "smoothed_specific_df = []\n",
    "traffic_parquet = pd.read_parquet(Path('data/traffic_data.parquet'))\n",
    "\n",
    "for num in SPECIFIC_INCIDENT_NUMS:\n",
    "    data_path = f'/home/karam-abu-judom/Sync/BME/2025_2026_1/Thesis/thesis_repo/data/incident_files/raw/incident_{num}.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "    raw_specific_df.append(df)\n",
    "    data_path = f'/home/karam-abu-judom/Sync/BME/2025_2026_1/Thesis/thesis_repo/data/incident_files/smoothed/incident_{num}.csv'\n",
    "    df = pd.read_csv(data_path)\n",
    "    smoothed_specific_df.append(df)\n",
    "\n",
    "print(f\"len(raw_specific_df): {len(raw_specific_df)}\")\n",
    "print(f\"len(smoothed_specific_df): {len(smoothed_specific_df)}\")\n",
    "print(f\"len(traffic_parquet): {len(traffic_parquet)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7babe09",
   "metadata": {},
   "source": [
    "Check if there are any NULL values in the CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209934ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = 0\n",
    "for df in raw_specific_df:\n",
    "    if df.isnull().values.any():\n",
    "        print(f\"Incident {num} contains NULL values.\")\n",
    "        null_count += 1\n",
    "    if len(df) != 3025:\n",
    "        print(f\"Incident {num} has {len(df)} rows instead of 3025.\")\n",
    "print(\"Raw check complete.\")\n",
    "for df in smoothed_specific_df:\n",
    "    if df.isnull().values.any():\n",
    "        print(f\"Incident {num} contains NULL values.\")\n",
    "        null_count += 1\n",
    "    if len(df) != 3025:\n",
    "        print(f\"Incident {num} has {len(df)} rows instead of 3025.\")\n",
    "print(\"Smoothed check complete.\")\n",
    "\n",
    "if null_count == 0:\n",
    "    print(\"No NULL values found in any of the selected incident files.\")\n",
    "else:\n",
    "    print(f\"NULL values found in {null_count} incident files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc57038",
   "metadata": {},
   "source": [
    "Summary statistics after and before smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['occ', 'speed', 'flow']\n",
    "summary=traffic_parquet[features].agg(['mean', 'median', 'std'])\n",
    "print(\"Summary for the parquet file:\")\n",
    "print(summary)\n",
    "print('------------------------------------------')\n",
    "smoothed_specific_df_concat = pd.concat(smoothed_specific_df, ignore_index=True)\n",
    "summary = smoothed_specific_df_concat[features].agg(['mean', 'median', 'std'])\n",
    "print(\"Summary for the 175 selected files (BEFORE SMOOTHING):\")\n",
    "print(summary)\n",
    "print('------------------------------------------')\n",
    "features = ['occ_smoothed', 'speed_smoothed']\n",
    "summary = smoothed_specific_df_concat[features].agg(['mean', 'median', 'std'])\n",
    "print(\"Summary for the 175 selected files (AFTER SMOOTHING):\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_plot = ['occ', 'speed', 'flow']\n",
    "labels = {'speed': 'Speed', 'occ': 'Occupancy', 'flow': 'Flow'}\n",
    "\n",
    "for col in vars_to_plot:\n",
    "    data = pd.to_numeric(traffic_parquet[col], errors='coerce').dropna()\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.histplot(data, kde=True, stat='density', bins=40, edgecolor='none', alpha=0.6, ax=ax)\n",
    "    sns.kdeplot(data, color='black', lw=1.2, ax=ax)\n",
    "    ax.set_title(f\"Distribution of {labels[col]}\")\n",
    "    ax.set_xlabel(labels[col])\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    save_and_close(fig, f\"distribution_{col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec2e3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hourly = traffic_parquet.copy()\n",
    "df_hourly['timestamp'] = pd.to_datetime(df_hourly['timestamp'], errors='coerce')\n",
    "for col in ['speed', 'occ', 'flow']:\n",
    "    df_hourly[col] = pd.to_numeric(df_hourly[col], errors='coerce')\n",
    "\n",
    "df_hourly['hour'] = df_hourly['timestamp'].dt.hour\n",
    "df_hourly['is_weekend'] = np.where(df_hourly['timestamp'].dt.dayofweek >= 5, 'Weekend', 'Weekday')\n",
    "agg_hour = df_hourly.groupby(['hour', 'is_weekend'])[['speed', 'occ', 'flow']].mean().reset_index()\n",
    "\n",
    "labels = {'speed': 'Speed', 'occ': 'Occupancy', 'flow': 'Flow'}\n",
    "for var in ['speed', 'occ', 'flow']:\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    sns.lineplot(data=agg_hour, x='hour', y=var, hue='is_weekend', marker='o', ax=ax)\n",
    "    ax.set_xticks(range(0, 24, 2))\n",
    "    ax.set_xlabel('Hour of Day')\n",
    "    ax.set_ylabel(f'Average {labels[var]}' + (' (mph)' if var == 'speed' else ''))\n",
    "    ax.set_title(f'Average {labels[var]} by Hour (Weekday vs Weekend)')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "    ax.legend(title='')\n",
    "    save_and_close(fig, f\"hourly_weekday_weekend_{var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01098262",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = traffic_parquet.copy()\n",
    "df_daily['timestamp'] = pd.to_datetime(df_daily['timestamp'], errors='coerce')\n",
    "for col in ['speed', 'occ', 'flow']:\n",
    "    df_daily[col] = pd.to_numeric(df_daily[col], errors='coerce')\n",
    "\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "df_daily['weekday'] = pd.Categorical(df_daily['timestamp'].dt.day_name(), categories=weekday_order, ordered=True)\n",
    "\n",
    "agg_day = df_daily.groupby('weekday', observed=True)[['speed', 'occ', 'flow']].mean().reset_index()\n",
    "\n",
    "labels = {'speed': 'Speed', 'occ': 'Occupancy', 'flow': 'Flow'}\n",
    "for var in ['speed', 'occ', 'flow']:\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    sns.lineplot(data=agg_day, x='weekday', y=var, marker='o', ax=ax, color='#4C72B0')\n",
    "    ax.set_xlabel('Day of Week')\n",
    "    ax.set_ylabel(f'Average {labels[var]}' + (' (mph)' if var == 'speed' else ''))\n",
    "    ax.set_title(f'Average {labels[var]} by Day of Week')\n",
    "    ax.tick_params(axis='x', rotation=30)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    save_and_close(fig, f\"weekday_average_{var}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = traffic_parquet[['speed', 'occ', 'flow']].apply(pd.to_numeric, errors='coerce')\n",
    "corr = df_corr.corr(method='pearson')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='vlag', vmin=-1, vmax=1, square=True, cbar_kws={'shrink': 0.8}, ax=ax)\n",
    "ax.set_title('Correlation Matrix')\n",
    "fig.tight_layout()\n",
    "save_and_close(fig, \"correlation_matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edae8d6",
   "metadata": {},
   "source": [
    "Check if there are any streams with multiple station IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94dc642",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in smoothed_specific_df:\n",
    "    unique_stations = df[\"station_id\"].unique()\n",
    "    if len(unique_stations) != 1:\n",
    "        print(f\"Stream {df['stream_id'].iloc[0]} has multiple station IDs: {unique_stations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ad2e56",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb32a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'smoothed_specific_df_concat' not in globals():\n",
    "    smoothed_specific_df_concat = pd.concat(smoothed_specific_df, ignore_index=True)\n",
    "\n",
    "df_cmp = smoothed_specific_df_concat[['speed', 'occ', 'flow', 'is_incident']].copy()\n",
    "for col in ['speed', 'occ', 'flow']:\n",
    "    df_cmp[col] = pd.to_numeric(df_cmp[col], errors='coerce')\n",
    "df_cmp = df_cmp.dropna(subset=['speed', 'occ', 'flow', 'is_incident'])\n",
    "df_cmp['is_incident'] = df_cmp['is_incident'].astype(int)\n",
    "\n",
    "agg = df_cmp.groupby('is_incident')[['speed', 'occ', 'flow']].mean().reset_index()\n",
    "\n",
    "labels = {'speed': 'Speed', 'occ': 'Occupancy', 'flow': 'Flow'}\n",
    "for var in ['speed', 'occ', 'flow']:\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.barplot(data=agg, x='is_incident', y=var, ax=ax, palette={'0': '#4C72B0', '1': '#DD8452'})\n",
    "    ax.set_xlabel('is_incident')\n",
    "    ax.set_ylabel(f'Average {labels[var]}' + (' (mph)' if var == 'speed' else ''))\n",
    "    ax.set_title(f'Average {labels[var]} by Incident Status')\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xticklabels(['0', '1'])\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "    save_and_close(fig, f\"incident_status_average_{var}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49d2239",
   "metadata": {},
   "source": [
    "Prove class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f2af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = smoothed_specific_df_concat['is_incident'].value_counts(normalize=True)\n",
    "print(\"Class distribution (percentage):\")\n",
    "print(class_counts * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ae7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'raw_specific_df_concat' not in globals():\n",
    "    raw_specific_df_concat = pd.concat(raw_specific_df, ignore_index=True)\n",
    "if 'smoothed_specific_df_concat' not in globals():\n",
    "    smoothed_specific_df_concat = pd.concat(smoothed_specific_df, ignore_index=True)\n",
    "\n",
    "raw = raw_specific_df_concat[['speed', 'occ']].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "smt = smoothed_specific_df_concat[['speed_smoothed', 'occ_smoothed']].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "# Speed KDE\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "spd_before = raw['speed'].dropna()\n",
    "spd_after = smt['speed_smoothed'].dropna()\n",
    "l_spd, r_spd = np.nanquantile(pd.concat([spd_before, spd_after]), [0.005, 0.995])\n",
    "sns.kdeplot(spd_before, ax=ax, lw=2, linestyle='--', color='#4C72B0', label='Before smoothing')\n",
    "sns.kdeplot(spd_after, ax=ax, lw=2, linestyle='-', color='#DD8452', label='After smoothing')\n",
    "ax.set_xlim(l_spd, r_spd)\n",
    "ax.set_title('KDE: Speed (Before vs After)')\n",
    "ax.set_xlabel('Speed')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "save_and_close(fig, \"kde_before_after_speed\")\n",
    "\n",
    "# Occupancy KDE\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "occ_before = raw['occ'].dropna()\n",
    "occ_after = smt['occ_smoothed'].dropna()\n",
    "l_occ, r_occ = np.nanquantile(pd.concat([occ_before, occ_after]), [0.005, 0.995])\n",
    "sns.kdeplot(occ_before, ax=ax, lw=2, linestyle='--', color='#4C72B0', label='Before smoothing')\n",
    "sns.kdeplot(occ_after, ax=ax, lw=2, linestyle='-', color='#DD8452', label='After smoothing')\n",
    "ax.set_xlim(l_occ, r_occ)\n",
    "ax.set_title('KDE: Occupancy (Before vs After)')\n",
    "ax.set_xlabel('Occupancy')\n",
    "ax.set_ylabel('Density')\n",
    "ax.legend()\n",
    "save_and_close(fig, \"kde_before_after_occupancy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c2b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrices: before vs after smoothing for (speed, occ)\n",
    "if 'raw_specific_df_concat' not in globals():\n",
    "    raw_specific_df_concat = pd.concat(raw_specific_df, ignore_index=True)\n",
    "if 'smoothed_specific_df_concat' not in globals():\n",
    "    smoothed_specific_df_concat = pd.concat(smoothed_specific_df, ignore_index=True)\n",
    "\n",
    "before = raw_specific_df_concat[['speed', 'occ']].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "after = smoothed_specific_df_concat[['speed_smoothed', 'occ_smoothed']].apply(pd.to_numeric, errors='coerce').dropna()\n",
    "\n",
    "corr_before = before.corr(method='pearson')\n",
    "corr_after = after.rename(columns={'speed_smoothed': 'speed', 'occ_smoothed': 'occ'}).corr(method='pearson')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3.5))\n",
    "sns.heatmap(corr_before, ax=axes[0], annot=True, vmin=-1, vmax=1, cmap='vlag', square=True, cbar=False, fmt='.2f')\n",
    "axes[0].set_title('Before smoothing')\n",
    "sns.heatmap(corr_after, ax=axes[1], annot=True, vmin=-1, vmax=1, cmap='vlag', square=True, cbar=True, fmt='.2f')\n",
    "axes[1].set_title('After smoothing')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e763ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "values_str = \"\"\"\n",
    "64.0428497501546\n",
    "66.4845064566845\n",
    "60.5140244022717\n",
    "67.7287537670514\n",
    "65.6851810433206\n",
    "63.9293956532458\n",
    "64.8880368312117\n",
    "64.4344827183552\n",
    "63.160430650206\n",
    "64.3010014916196\n",
    "63.5298288661391\n",
    "65.4878787954852\n",
    "63.3840790634106\n",
    "62.7551380905519\n",
    "60.4307449168042\n",
    "63.2248760164877\n",
    "64.5592665882068\n",
    "65.9933374512893\n",
    "65.4536705879877\n",
    "67.5287936650416\n",
    "68.1797520222228\n",
    "64.9101406605332\n",
    "66.8771616193769\n",
    "62.7757056789689\n",
    "66.5119104851205\n",
    "69.6110817845193\n",
    "69.0628293790384\n",
    "67.0869408579196\n",
    "64.5468199685855\n",
    "62.5584791504994\n",
    "63.9110417171196\n",
    "67.9880163971468\n",
    "64.6771249285006\n",
    "66.879693670052\n",
    "65.7661157462282\n",
    "65.2483861811579\n",
    "67.5642717927854\n",
    "68.1061828511886\n",
    "60.6714687196863\n",
    "68.8630242464429\n",
    "63.987935787281\n",
    "65.4693940806477\n",
    "68.4600535180971\n",
    "66.2991038692718\n",
    "66.931539176185\n",
    "64.8136565488189\n",
    "69.8843671416875\n",
    "65.8306200037577\n",
    "64.2641783529849\n",
    "66.9613930923003\n",
    "63.6472694770959\n",
    "68.4100516324664\n",
    "63.1370529539883\n",
    "65.6117714013936\n",
    "64.3430972060437\n",
    "67.9986044168803\n",
    "66\n",
    "67.4426360974599\n",
    "66.6957622903781\n",
    "66.6181003974595\n",
    "66.7156932352367\n",
    "69.3355991880659\n",
    "64.7059376430073\n",
    "64.1427634264825\n",
    "64.0374094340654\n",
    "63.2821192980197\n",
    "62.0792710835178\n",
    "63.2694228089777\n",
    "61.5802045953994\n",
    "66.9575346221104\n",
    "63.7788666253082\n",
    "61.5095972088597\n",
    "62.66741199212\n",
    "58.2865464895981\n",
    "63.5986122533404\n",
    "63.0044750002337\n",
    "64.1749180837489\n",
    "62.9036882875965\n",
    "61.5027500535088\n",
    "61.317269693735\n",
    "63.5855002685223\n",
    "65.3863814390491\n",
    "67.4930223136056\n",
    "72.1703576357762\n",
    "61.8797252827615\n",
    "61.2228122550815\n",
    "67.7387872807456\n",
    "63.6196004594271\n",
    "65.7014160885027\n",
    "64.7312818557198\n",
    "64.3007042342333\n",
    "66.7198485640535\n",
    "63.5755310922839\n",
    "64.4732986335181\n",
    "66.6691529936942\n",
    "65.7624580333693\n",
    "66.0524459337248\n",
    "65.2569537532023\n",
    "68.0372311302682\n",
    "\"\"\".strip()\n",
    "\n",
    "vals = [float(x) for x in values_str.splitlines() if x.strip()]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "sns.histplot(vals, bins=30, stat='count', color='#4C72B0', edgecolor='white', alpha=0.85, kde=True, ax=ax)\n",
    "ax.set_title('Histogram of speeds (cell 23)')\n",
    "ax.set_xlabel('Speed (mph)')\n",
    "ax.set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb88fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the mean and median flow values for data/traffic_data.parquet\n",
    "traffic_data = pd.read_parquet(Path('data/traffic_data.parquet'))\n",
    "mean_flow = traffic_data['flow'].mean()\n",
    "median_flow = traffic_data['flow'].median()\n",
    "print(f\"Mean flow: {mean_flow}\"\n",
    "      f\"\\nMedian flow: {median_flow}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
